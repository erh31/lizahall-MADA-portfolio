[
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Summary/Abstract",
    "section": "",
    "text": "PATRICK KAGGWA contributed to this exercise."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Summary/Abstract",
    "section": "General Background Information",
    "text": "General Background Information\nThis exercise was done as part of an assignment and is educational in nature. The premise of the assignment was the cleaning, processing, and analysis of a provided “unclean” data set via manipulation with R and RStudio. The exercise was also meant to encourage collaboration between classmates, in preparation for future collaboration involving scientific data."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Summary/Abstract",
    "section": "Description of data and data source",
    "text": "Description of data and data source\nData included variables of ‘height’, ‘weight’, ‘gender’, ‘age’ and ‘hair color’. Each variable had 14 associated values which were either numeric or categorical.\nThe data was provided via Andreas Handel and Liza Hall."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-acquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-acquisition",
    "title": "Summary/Abstract",
    "section": "Data acquisition",
    "text": "Data acquisition\nData for ‘Height’, ‘Weight’, and ‘Gender’ were provided by Andreas Handel.\nData for ‘Age’ and ‘Hair Color’ were provided by Liza Hall, and were chosen using random generators available online (age generator)."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Summary/Abstract",
    "section": "Data import and cleaning",
    "text": "Data import and cleaning\nThis part of the exercise was done by Patrick Kaggwa. All files can be found on Github in the ‘starter-analysis-exercise’ folder.\nData was imported, processed, and cleaned in RStudio using the following script:\n---\ntitle: \"An example cleaning script\"\nauthor: \"Patrick Kaggwa\"\ndate: \"2023-01-03\"\noutput: html_document\n---\n\n\n# Processing script\n\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\n# Setup\n\nLoad needed packages. make sure they are installed.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n```\n:::\n\n\n# Data loading\n\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so:\npackage::function() that's not required one could just call the function specifying the package makes it clearer where the function \"lives\",\nbut it adds typing. You can do it either way.\n\n::: {.cell}\n\n```{.r .cell-code}\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n```\n:::\n\n\n# Check data\n\nFirst we can look at the codebook\n\n::: {.cell}\n\n```{.r .cell-code}\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                         `Allowed Values`\n  &lt;chr&gt;           &lt;chr&gt;                                         &lt;chr&gt;           \n1 Height          height in centimeters                         numeric value &gt;…\n2 Weight          weight in kilograms                           numeric value &gt;…\n3 Gender          identified gender (male/female/other)         M/F/O/NA        \n4 Age             age in years                                  numeric value &gt;0\n5 Hair Color      hair color (black, brown, blonde, red, other) Blk, Bro, Bln, …\n```\n\n\n:::\n:::\n\n\nSeveral ways of looking at the data\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::glimpse(rawdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 14\nColumns: 5\n$ Height       &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"…\n$ Weight       &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender       &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"…\n$ Age          &lt;dbl&gt; 26, 41, 58, 18, 58, 59, 24, 30, 20, 57, 40, 41, 57, 43\n$ `Hair Color` &lt;chr&gt; \"Bro\", \"Bro\", \"Bro\", \"Oth\", \"Bro\", \"Bln\", \"Blk\", \"Bro\", \"…\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(rawdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Height              Weight          Gender               Age       \n Length:14          Min.   :  45.0   Length:14          Min.   :18.00  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.:27.00  \n Mode  :character   Median :  70.0   Mode  :character   Median :41.00  \n                    Mean   : 602.7                      Mean   :40.86  \n                    3rd Qu.:  90.0                      3rd Qu.:57.00  \n                    Max.   :7000.0                      Max.   :59.00  \n                    NA's   :1                                          \n  Hair Color       \n Length:14         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n```\n\n\n:::\n\n```{.r .cell-code}\nhead(rawdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  Height Weight Gender   Age `Hair Color`\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;       \n1 180        80 M         26 Bro         \n2 175        70 O         41 Bro         \n3 sixty      60 F         58 Bro         \n4 178        76 F         18 Oth         \n5 192        90 NA        58 Bro         \n6 6          55 F         59 Bln         \n```\n\n\n:::\n\n```{.r .cell-code}\nskimr::skim(rawdata)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |rawdata |\n|Number of rows           |14      |\n|Number of columns        |5       |\n|_______________________  |        |\n|Column type frequency:   |        |\n|character                |3       |\n|numeric                  |2       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Height        |         0|             1|   1|   5|     0|       13|          0|\n|Gender        |         0|             1|   1|   2|     0|        5|          0|\n|Hair Color    |         0|             1|   3|   3|     0|        5|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|      sd| p0| p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-------:|--:|---:|---:|---:|----:|:-----|\n|Weight        |         1|          0.93| 602.69| 1922.25| 45|  55|  70|  90| 7000|▇▁▁▁▁ |\n|Age           |         0|          1.00|  40.86|   15.25| 18|  27|  41|  57|   59|▆▂▅▂▇ |\n\n\n:::\n:::\n\n\n\n# Cleaning\n\nBy inspecting the data as done above, we find some problems that need addressing:\n\nFirst, there is an entry for height which says \"sixty\" instead of a number. \nDoes that mean it should be a numeric 60? It somehow doesn't make sense since the weight is 60kg, which can't happen for a 60cm person (a baby).\nSince we don't know how to fix this, we might decide to remove the person. This \"sixty\" entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn't very meaningful. So let's fix that first.\n\n::: {.cell}\n\n```{.r .cell-code}\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d1   |\n|Number of rows           |13   |\n|Number of columns        |5    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |2    |\n|numeric                  |3    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Gender        |         0|             1|   1|   2|     0|        5|          0|\n|Hair Color    |         0|             1|   3|   3|     0|        5|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|      sd| p0|    p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-------:|--:|------:|---:|---:|----:|:-----|\n|Height        |         0|          1.00| 151.62|   46.46|  6| 154.00| 165| 175|  192|▁▁▁▂▇ |\n|Weight        |         1|          0.92| 647.92| 2000.48| 45|  54.75|  73|  90| 7000|▇▁▁▁▁ |\n|Age           |         0|          1.00|  39.54|   15.02| 18|  26.00|  41|  57|   59|▇▂▆▂▇ |\n\n\n:::\n\n```{.r .cell-code}\nhist(d1$Height)\n```\n\n::: {.cell-output-display}\n![](starter-analysis-report_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don't know, we might need to remove this person, which we'll do here.\n\n::: {.cell}\n\n```{.r .cell-code}\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d2   |\n|Number of rows           |13   |\n|Number of columns        |5    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |2    |\n|numeric                  |3    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Gender        |         0|             1|   1|   2|     0|        5|          0|\n|Hair Color    |         0|             1|   3|   3|     0|        5|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|      sd|  p0|    p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-------:|---:|------:|---:|---:|----:|:-----|\n|Height        |         0|          1.00| 165.23|   16.52| 133| 155.00| 166| 178|  192|▂▇▆▆▃ |\n|Weight        |         1|          0.92| 647.92| 2000.48|  45|  54.75|  73|  90| 7000|▇▁▁▁▁ |\n|Age           |         0|          1.00|  39.54|   15.02|  18|  26.00|  41|  57|   59|▇▂▆▂▇ |\n\n\n:::\n:::\n\nHeight values seem ok now.\n\nNow let's look at the `Weight` variable. There is a person with weight of 7000, which is impossible, and one person with missing weight.\nTo be able to analyze the data, we'll remove those individuals as well.\n\n::: {.cell}\n\n```{.r .cell-code}\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d3   |\n|Number of rows           |11   |\n|Number of columns        |5    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |2    |\n|numeric                  |3    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Gender        |         0|             1|   1|   2|     0|        5|          0|\n|Hair Color    |         0|             1|   3|   3|     0|        4|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd|  p0|   p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|---:|-----:|---:|---:|----:|:-----|\n|Height        |         0|             1| 167.09| 16.81| 133| 155.5| 166| 179|  192|▂▇▅▇▅ |\n|Weight        |         0|             1|  70.45| 20.65|  45|  54.5|  70|  85|  110|▇▂▃▃▂ |\n|Age           |         0|             1|  37.91| 15.40|  18|  25.0|  41|  50|   59|▇▂▃▂▆ |\n\n\n:::\n:::\n\nNow checking the `Gender` variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\n::: {.cell}\n\n```{.r .cell-code}\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d3   |\n|Number of rows           |11   |\n|Number of columns        |5    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |1    |\n|factor                   |1    |\n|numeric                  |3    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Hair Color    |         0|             1|   3|   3|     0|        4|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts             |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------------|\n|Gender        |         0|             1|FALSE   |        5|M: 4, F: 3, O: 2, N: 1 |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd|  p0|   p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|---:|-----:|---:|---:|----:|:-----|\n|Height        |         0|             1| 167.09| 16.81| 133| 155.5| 166| 179|  192|▂▇▅▇▅ |\n|Weight        |         0|             1|  70.45| 20.65|  45|  54.5|  70|  85|  110|▇▂▃▃▂ |\n|Age           |         0|             1|  37.91| 15.40|  18|  25.0|  41|  50|   59|▇▂▃▂▆ |\n\n\n:::\n:::\n\n\nNow we see that there is another NA, but it's not `NA` from R, instead it was loaded as character and is now considered as a category.\nWell proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I'm also using droplevels() to get rid of it.\n\n::: {.cell}\n\n```{.r .cell-code}\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d4   |\n|Number of rows           |9    |\n|Number of columns        |5    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |1    |\n|factor                   |1    |\n|numeric                  |3    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Hair Color    |         0|             1|   3|   3|     0|        4|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts       |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------|\n|Gender        |         0|             1|FALSE   |        3|M: 4, F: 3, O: 2 |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd|  p0| p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|---:|---:|---:|---:|----:|:-----|\n|Height        |         0|             1| 165.67| 15.98| 133| 156| 166| 178|  183|▂▁▃▃▇ |\n|Weight        |         0|             1|  70.11| 21.25|  45|  55|  70|  80|  110|▇▂▃▂▂ |\n|Age           |         0|             1|  37.67| 14.35|  18|  26|  41|  43|   59|▇▂▅▂▅ |\n\n\n:::\n:::\n\n\nAll done, data is clean now. \n\nLet's assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\n::: {.cell}\n\n```{.r .cell-code}\nprocesseddata &lt;- d4\n```\n:::\n\n\n# Save data \n\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. \nThis preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.\nHowever, CSV is better for sharing with others since it's plain text. If you do CSV, you might want to write down somewhere what each variable is.\n\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n```\n:::\n\nNote the use of the `here` package and `here` command to specify a path relative to the main project directory, that is the folder that contains the `.Rproj` file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\n\n# Notes\n\nRemoving anyone observation with \"faulty\" or missing data is one approach. It's often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Summary/Abstract",
    "section": "Statistical analysis",
    "text": "Statistical analysis\nStatistical analysis for Table 1 was done using the following code.\n############################\n#### Third model fit\n# fit linear model using height as outcome, hair color and age as predictors\n\nlmfit3 &lt;- lm(Height ~ `Hair Color` + `Age`, mydata)  \n\n# place results from fit into a data frame with the tidy function\nlmtable3 &lt;- broom::tidy(lmfit3)\n\n#look at fit results\nprint(lmtable3)\n\n# save fit results table  \ntable_file3 = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"resulttable3.rds\")\nsaveRDS(lmtable3, file = table_file3)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#figures-and-tables",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#figures-and-tables",
    "title": "Summary/Abstract",
    "section": "Figures and Tables",
    "text": "Figures and Tables\nFigures were generated by Patrick Kaggwa, tables were produced by Liza Hall.\n\nFigure 1. Height distribution histogram\n\nFigure 2. Weight distribution histogram\n\nFigure 3. Scatter plot with linear regression fit depicting the relationship between height and weight\n\nFigure 4. Scatter plot with gender-stratified linear regression fits illustrating the relationship between height and weight\nA tibble 5x5\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np. value\n\n\n1\n(Intercept)\n156.\n25.5\n6.12\n0.00367\n\n\n2\n‘Hair Color’ Bln\n2.06\n30.0\n0.0687\n0.949\n\n\n3\n‘Hair Color’ Bro\n15.8\n24.7\n0.639\n0.558\n\n\n4\n‘Hair Color’ Oth\n10.0\n25.5\n0.393\n0.714\n\n\n5\nAge\n-0.00238\n0.633\n-0.00376\n0.997\n\n\n\nTable 1. Table of outcomes from a fit linear model using height as outcome and hair color and age as predictors"
  },
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/lizahall-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                         `Allowed Values`\n  &lt;chr&gt;           &lt;chr&gt;                                         &lt;chr&gt;           \n1 Height          height in centimeters                         numeric value &gt;…\n2 Weight          weight in kilograms                           numeric value &gt;…\n3 Gender          identified gender (male/female/other)         M/F/O/NA        \n4 Age             age in years                                  numeric value &gt;0\n5 Hair Color      hair color (black, brown, blonde, red, other) Blk, Bro, Bln, …\n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height       &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"…\n$ Weight       &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender       &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"…\n$ Age          &lt;dbl&gt; 26, 41, 58, 18, 58, 59, 24, 30, 20, 57, 40, 41, 57, 43\n$ `Hair Color` &lt;chr&gt; \"Bro\", \"Bro\", \"Bro\", \"Oth\", \"Bro\", \"Bln\", \"Blk\", \"Bro\", \"…\n\nsummary(rawdata)\n\n    Height              Weight          Gender               Age       \n Length:14          Min.   :  45.0   Length:14          Min.   :18.00  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.:27.00  \n Mode  :character   Median :  70.0   Mode  :character   Median :41.00  \n                    Mean   : 602.7                      Mean   :40.86  \n                    3rd Qu.:  90.0                      3rd Qu.:57.00  \n                    Max.   :7000.0                      Max.   :59.00  \n                    NA's   :1                                          \n  Hair Color       \n Length:14         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender   Age `Hair Color`\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;       \n1 180        80 M         26 Bro         \n2 175        70 O         41 Bro         \n3 sixty      60 F         58 Bro         \n4 178        76 F         18 Oth         \n5 192        90 NA        58 Bro         \n6 6          55 F         59 Bln         \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n3\n3\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55\n70\n90\n7000\n▇▁▁▁▁\n\n\nAge\n0\n1.00\n40.86\n15.25\n18\n27\n41\n57\n59\n▆▂▅▂▇\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n3\n3\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nAge\n0\n1.00\n39.54\n15.02\n18\n26.00\n41\n57\n59\n▇▂▆▂▇\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n3\n3\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nAge\n0\n1.00\n39.54\n15.02\n18\n26.00\n41\n57\n59\n▇▂▆▂▇\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n3\n3\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\nAge\n0\n1\n37.91\n15.40\n18\n25.0\n41\n50\n59\n▇▂▃▂▆\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHair Color\n0\n1\n3\n3\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\nAge\n0\n1\n37.91\n15.40\n18\n25.0\n41\n50\n59\n▇▂▃▂▆\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHair Color\n0\n1\n3\n3\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nAge\n0\n1\n37.67\n14.35\n18\n26\n41\n43\n59\n▇▂▅▂▅\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/lizahall-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Hair Color            0             1   3   3     0        4          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 Age                   0             1  37.7 14.4  18  26  41  43   59 ▇▂▅▂▅\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "Placeholder file for the future data/results presentation exercise."
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise",
    "section": "",
    "text": "Creating the Dataset\nLoad required packages, and set seed.\n# load required packages\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(here)\nlibrary(httr)\n\n# set seed for reproducibility \nset.seed(234)\nSet number of artists and songs, and create empty dataframe.\n\n# Set the number of songs and artists\nn_songs &lt;- 300\nn_artists &lt;- 20\n\n# Create an empty data frame with placeholders for music-related variables\nmusic_data &lt;- data.frame(\nSongID = 1:n_songs,\nTitle = character(n_songs),\nArtist = character(n_songs),\nGenre = character(n_songs),\nBPM = numeric(n_songs),\nDanceability = numeric(n_songs),\nLengthInSeconds = numeric(n_songs),\nReleaseYear = integer(n_songs),\nRating = numeric(n_songs)\n)\n\nCreate a vector of artists names, adjectives, and nouns. This will be used to assign an artist name and to generate random song names. (This part was overkill but I thought it was fun.)\n\n# Define a vector of artist names\n# I used a random name generator (https://igenerator.net/random-name-generator/artist-name-generator/) to generate names\n# I also used this random band name generator (https://rocklou.com/bandnamegenerator)\nartist_names &lt;- c(\"Ophelia Onyx\", \"Raina Ruby\", \"Grayson Knight\", \"Atlas Stonehart\", \"Indigo Stone\",\n                  \"Jasper Wolf\", \"Alex Ace\", \"Gary Joy\", \"JTK\", \"Julian Howard\", \n                  \"LLAP\", \"Grey Century\", \"Coven Atmosphere\", \"Eternal Symphonies\", \"The Inner Ethers\",\n                  \"The Whirlwind\", \"H.E.A.V.Y\", \"Orange Vinyl\", \"Days Of Cities\", \"Enterprise\")\n\n# Ensure there are exactly 20 names in the vector\nif(length(artist_names) != 20) {\n  stop(\"The number of artist names should be exactly 20.\")\n}\n  \n# Generating random song titles (probably overkill but I think its fun)\n# I used this random word generator (https://randomwordgenerator.com)\ngenerate_random_title &lt;- function() {\n\n  adjectives &lt;- c(\"Lame\", \"Towering\", \"Ambiguous\", \"Vagabond\", \"Limping\",\n                  \"Quarrelsome\", \"Guiltless\", \"Vengeful\", \"Quirky\", \"Chief\",\n                  \"Worried\", \"Simple\", \"Redundant\", \"Charming\", \"Jobless\",\n                  \"Impossible\", \"False\", \"Significant\", \"Secretive\", \"Lackadaisical\",\n                  \"Alive\", \"Disillusioned\", \"Thin\", \"Legal\", \"Unhappy\",\n                  \"Dangerous\", \"Vivacious\", \"Important\", \"Wistful\", \"Condemned\")\n  \n       nouns &lt;- c(\"Penalty\", \"Camera\", \"Leader\", \"Membership\", \"Oven\",\n                  \"Promotion\", \"Wealth\", \"Lake\", \"Drama\", \"Map\",\n                  \"Cabinet\", \"Quality\", \"Television\", \"Guest\", \"Bath\",\n                  \"Bonus\", \"Soup\", \"Agency\", \"Insect\", \"Person\",\n                  \"Student\", \"Nation\", \"Manufacturer\", \"Player\", \"Year\",\n                  \"Consequence\", \"Meal\", \"Presence\", \"Environment\", \"Criticism\")\n  \n  random_adjective &lt;- sample(adjectives, 1)\n  random_noun &lt;- sample(nouns, 1)\n  title &lt;- paste(random_adjective, random_noun, sep = \" \")\n  return(title)\n}\n\nGenerating synthetic data.\n\n# Generate synthetic data for music-related variables\nmusic_data$Title &lt;- replicate(n_songs, generate_random_title())\nmusic_data$Artist &lt;- sample(artist_names, n_songs, replace = TRUE)\nmusic_data$Genre &lt;- sample(c(\"Pop\", \"Rock\", \"Hip-Hop\", \"Electronic\", \"Jazz\"), n_songs, replace = TRUE)\nmusic_data$BPM &lt;- round(rnorm(n_songs, mean = 120, sd = 20))\nmusic_data$Danceability &lt;- round(pmax(pmin(runif(n_songs, min = 1, max = 10), 10), 1))\nmusic_data$LengthInSeconds &lt;- round(rnorm(n_songs, mean = 240, sd = 30))\nmusic_data$ReleaseYear &lt;- sample(1950:2020, n_songs, replace = TRUE)\nmusic_data$Rating &lt;- round(pmax(pmin(rnorm(n_songs, mean = 3.5, sd = 1), 10), 1))\n\n\n\nIntroducing Dependencies Between Variables\nAssigning artists a primary genre.\n\n# Artists produce songs in a primary genre, but occasionally produce songs from other genres\nartists &lt;- paste0(\"Artist\", 1:n_artists)\nprimary_genres &lt;- sample(c(\"Pop\", \"Rock\", \"Hip-Hop\", \"Electronic\", \"Jazz\"), n_artists, replace = TRUE)\nartist_genre_mapping &lt;- data.frame(Artist = artists, PrimaryGenre = primary_genres)\nfraction_other_genres &lt;- 0.2\nfor (i in 1:n_artists) {\n  artist_songs &lt;- music_data$Artist == artists[i]\n  primary_genre &lt;- artist_genre_mapping$PrimaryGenre[i]\n  if (any(artist_songs)) {\n    num_songs_total &lt;- sum(artist_songs)\n    num_other_genres &lt;- round(num_songs_total * fraction_other_genres)\n    other_indices &lt;- sample(which(artist_songs), num_other_genres)\n    music_data$Genre[other_indices] &lt;- sample(setdiff(c(\"Pop\", \"Rock\", \"Hip-Hop\", \"Electronic\", \"Jazz\"), primary_genre), num_other_genres, replace = TRUE)\n    music_data$Genre[setdiff(which(artist_songs), other_indices)] &lt;- primary_genre\n  }\n}\n\nGenre effects average BPM.\n\n# Songs in Jazz and Pop genres tend to have higher BPMs\nfraction_adjust_bpm_jazz_pop &lt;- 0.8 \njazz_pop_indices &lt;- which(music_data$Genre %in% c(\"Jazz\", \"Pop\") & runif(n_songs) &lt; fraction_adjust_bpm_jazz_pop)\nmusic_data$BPM[jazz_pop_indices] &lt;- music_data$BPM[jazz_pop_indices] + 20\n\n# Songs in the Rock and Hip-Hop genres tend to have lower BPMs\nfraction_adjust_bpm_hip_hop &lt;- 0.8\nhip_hop_indices &lt;- which(music_data$Genre %in% c(\"Hip-Hop\") & runif(n_songs) &lt; fraction_adjust_bpm_hip_hop)\nmusic_data$BPM[hip_hop_indices] &lt;- music_data$BPM[hip_hop_indices] - 10\nfraction_adjust_bpm_rock &lt;- 0.6\nrock_indices &lt;- which(music_data$Genre %in% c(\"Rock\") & runif(n_songs) &lt; fraction_adjust_bpm_rock)\nmusic_data$BPM[rock_indices] &lt;- music_data$BPM[rock_indices] - 10\n\nDanceability effects ratings. BPM range effects danceability.\n\n# Songs with higher danceability tend to have higher ratings\nmusic_data$Rating[music_data$Danceability &gt; 5] &lt;- music_data$Rating[music_data$Danceability &gt; 5] + 3\n\n# Songs between 115-125 BPM get a boost in danceability\nbpm_boost_indices &lt;- which(music_data$BPM &gt;= 115 & music_data$BPM &lt;= 125)\nmusic_data$Danceability[bpm_boost_indices] &lt;- music_data$Danceability[bpm_boost_indices] + 3\n\nGenre effects release year.\n\n# Songs in the Rock and Jazz genres tend to be older\nfraction_replace_jazz &lt;- 0.7  \nfraction_replace_rock &lt;- 0.6  \njazz_indices &lt;- which(music_data$Genre %in% c(\"Jazz\") & runif(n_songs) &lt; fraction_replace_jazz)\nrock_indices &lt;- which(music_data$Genre %in% c(\"Rock\") & runif(n_songs) &lt; fraction_replace_rock)\nmusic_data$ReleaseYear[jazz_indices] &lt;- sample(c(1950:1970), length(jazz_indices), replace = TRUE)\nmusic_data$ReleaseYear[rock_indices] &lt;- sample(c(1970:2000), length(rock_indices), replace = TRUE)\n\n# Songs in the Pop and Electronic genres tend to be newer\nfraction_replace_electronic &lt;- 0.6  \nfraction_replace_pop &lt;- 0.5  \nelectronic_indices &lt;- which(music_data$Genre %in% c(\"Electronic\") & runif(n_songs) &lt; fraction_replace_electronic)\npop_indices &lt;- which(music_data$Genre %in% c(\"Pop\") & runif(n_songs) &lt; fraction_replace_pop)\nmusic_data$ReleaseYear[electronic_indices] &lt;- sample(c(1990:2010), length(electronic_indices), replace = TRUE)\nmusic_data$ReleaseYear[pop_indices] &lt;- sample(c(2000:2020), length(pop_indices), replace = TRUE)\n\n\n\nAnalyzing and Displaying the Data\nGeneral summary of data.\n\n# Display the first few rows of the synthetic music dataset\nhead(music_data)\n\n  SongID                  Title           Artist      Genre BPM Danceability\n1      1            Lame Camera      Jasper Wolf        Pop 167            6\n2      2        Charming Camera      Jasper Wolf       Rock 129            4\n3      3 Significant Television The Inner Ethers       Rock 100            8\n4      4          Legal Penalty The Inner Ethers    Hip-Hop 137            2\n5      5    Vagabond Membership     Indigo Stone Electronic 166            5\n6      6            Thin Nation              JTK       Rock 123            4\n  LengthInSeconds ReleaseYear Rating\n1             228        2019      6\n2             213        1959      4\n3             245        1979      7\n4             238        1971      4\n5             226        2009      4\n6             264        1970      4\n\n\n\nBar plot for genre vs BPM. This is to show the correlation between genre and BPM.\n\n# Bar plot for Genre vs BPM\nggplot(music_data, aes(x = Genre, y = BPM, fill = Genre)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Genre vs BPM in Synthetic Music Dataset\",\n       x = \"Genre\",\n       y = \"BPM\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nScatter plot for BPM and danceability. This is to show the correlation between BPM and danceability.\n\n# Scatter plot for BPM and Danceability\nggplot(music_data, aes(x = BPM, y = Danceability, color = Genre)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of BPM and Danceability\",\n       x = \"BPM\",\n       y = \"Danceability\",\n       color = \"Genre\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBoxplot for ratings across genres.\n\n# Boxplot for Ratings across Genres\nggplot(music_data, aes(x = Genre, y = Rating, fill = Genre)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Ratings Across Genres\",\n       x = \"Genre\",\n       y = \"Rating\",\n       fill = \"Genre\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBoxplot for genres across years. This is to show how genre affects release year.\n\n# Boxplot for Genres across Years\nggplot(music_data, aes(x = Genre, y = ReleaseYear, fill = Genre)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Genres Across Years\",\n       x = \"Genre\",\n       y = \"Release Year\",\n       fill = \"Genre\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBar plot for danceability vs ratings. This is to show the relationship between ratings and danceability.\n\n# Bar plot for Danceability vs Ratings\nggplot(music_data, aes(x = Danceability, y = Rating, fill = factor(Danceability))) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Bar Graph of Danceability vs Ratings\",\n       x = \"Danceability\",\n       y = \"Rating\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBar plot for selected artists vs genre. This is to show that artists were assigned a primary genre.\n\n# Selecting only half of the artists for better visibility\nselected_artists &lt;- sample(artist_names, n_artists / 2)\n\n# Bar plot for Selected Artists vs Genre\nggplot(music_data[music_data$Artist %in% selected_artists, ], \n       aes(x = Artist, fill = Genre)) +\n  geom_bar(stat = \"count\") +\n  labs(title = \"Bar Graph of Selected Artists vs Genre of Songs Produced\",\n       x = \"Artist\",\n       y = \"Count\",\n       fill = \"Genre\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\nTable of the top rated songs, just for fun.\n\n# Creating a data frame with top-rated songs\ntop_rated_songs &lt;- music_data[order(music_data$Rating, decreasing = TRUE), ]\n\n# Selecting the top 10 rated songs (you can adjust the number as needed)\ntop_rated_songs &lt;- head(top_rated_songs, 10)\n\n# Displaying the table with Song Title, Artist, Genre, and Rating\ntop_rated_songs_table &lt;- data.frame(Song_Title = top_rated_songs$Title,\n                                    Artist = top_rated_songs$Artist,\n                                    Genre = top_rated_songs$Genre,\n                                    Rating = top_rated_songs$Rating)\n\nprint(top_rated_songs_table)\n\n           Song_Title             Artist      Genre Rating\n1   Impossible Player         Enterprise Electronic      9\n2       Jobless Guest Eternal Symphonies       Jazz      8\n3    Ambiguous Insect        Jasper Wolf    Hip-Hop      8\n4    Secretive Wealth         Raina Ruby       Jazz      8\n5        Thin Penalty   The Inner Ethers       Rock      8\n6  Redundant Presence Eternal Symphonies        Pop      8\n7         Thin Wealth      Julian Howard Electronic      8\n8    Lame Consequence           Gary Joy       Rock      8\n9    Dangerous Leader        Jasper Wolf    Hip-Hop      8\n10   Worried Presence           Alex Ace        Pop      8\n\n\n\nLinear model for rating with BPM and danceability as predictors.\nThis produces a p-value of 2.2e-16 which indicates signifigance.\n\n# Fit a linear model for Rating with BPM and Danceability as predictors.\nlinear_model &lt;- lm(Rating ~ BPM + Danceability, data = music_data)\nsummary(linear_model)\n\n\nCall:\nlm(formula = Rating ~ BPM + Danceability, data = music_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7677 -1.0787 -0.0488  0.9247  3.0917 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.4461375  0.4444838   5.503 8.06e-08 ***\nBPM          -0.0003266  0.0032833  -0.099    0.921    \nDanceability  0.4198899  0.0280700  14.959  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.378 on 297 degrees of freedom\nMultiple R-squared:  0.4298,    Adjusted R-squared:  0.4259 \nF-statistic: 111.9 on 2 and 297 DF,  p-value: &lt; 2.2e-16\n\n\n\nLinear model for BPM with genre as a predictor.\nThis produces a p-value of 2.2e-16 which indicates signifigance.\n\n# Fit a linear model for BPM with Genre as a predictor.\nlinear_model_rating_interaction &lt;- lm(BPM ~ Genre, data = music_data)\nsummary(linear_model_rating_interaction)\n\n\nCall:\nlm(formula = BPM ~ Genre, data = music_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-62.138 -13.686   0.662  14.896  55.325 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   127.000      2.691  47.193  &lt; 2e-16 ***\nGenreHip-Hop  -17.542      4.037  -4.346 1.91e-05 ***\nGenreJazz      11.138      3.732   2.985  0.00308 ** \nGenrePop       11.720      3.991   2.936  0.00358 ** \nGenreRock     -16.325      3.590  -4.548 7.92e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.84 on 295 degrees of freedom\nMultiple R-squared:  0.2731,    Adjusted R-squared:  0.2632 \nF-statistic:  27.7 on 4 and 295 DF,  p-value: &lt; 2.2e-16\n\n\n\nLinear model for release year with genre as a predictor.\nThis produces a p-value of 2.2e-16 which indicates signifigance.\n\n# Fit a linear model for Release Year with Genre as a predictor.\nlinear_model_genre_year &lt;- lm(ReleaseYear ~ Genre, data = music_data)\nsummary(linear_model_genre_year)\n\n\nCall:\nlm(formula = ReleaseYear ~ Genre, data = music_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.617 -11.558  -0.477  11.900  48.523 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1994.617      2.390 834.638  &lt; 2e-16 ***\nGenreHip-Hop   -8.992      3.585  -2.508   0.0127 *  \nGenreJazz     -28.140      3.314  -8.491 1.02e-15 ***\nGenrePop        3.483      3.545   0.983   0.3266    \nGenreRock      -8.058      3.188  -2.528   0.0120 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.51 on 295 degrees of freedom\nMultiple R-squared:  0.2655,    Adjusted R-squared:  0.2555 \nF-statistic: 26.65 on 4 and 295 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html",
    "href": "cdcdata-exercise/cdcdata-exercise.html",
    "title": "CDC Data Exercise",
    "section": "",
    "text": "This dataset is the ‘Monthly Provisional Counts of Deaths by Select Causes, 2020-2023’ though for the purpose of this exercise I am only using data from 2020-2022.\nThe dataset can be found here:\nhttps://data.cdc.gov/NCHS/Monthly-Provisional-Counts-of-Deaths-by-Select-Cau/9dzk-mvmi/about_data\nAfter cleaning the dataset contains the following list of variables:\n\nJurisdiction of Occurrence\nYear\nMonth\nNumber Of Days\nAll Cause\nNatural Cause\nSepticemia\nMalignant Neoplasms\nDiabetes Mellitus\nAlzheimer Disease\nInfluenza and Pneumonia\nChronic Lower Respiratory Diseases\nOther Diseases of Respiratory System\nNephritis/Nephrotic Syndrome and Nephrosis\nAbnormal Findings (No Classifiable Diagnosis)\nDiseases of Heart\nCerebrovascular Diseases\nAccidents/Unintentional Injuries\nMotor Vehicle Accidents\nIntentional Self Harm/Suicide\nAssault/Homicide\nDrug Overdose\nCOVID 19/Multiple Cause of Death\nCOVID 19/Underlying Cause of Death"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#this-section-is-contributed-by-chaohua-li",
    "href": "cdcdata-exercise/cdcdata-exercise.html#this-section-is-contributed-by-chaohua-li",
    "title": "CDC Data Exercise",
    "section": "This section is contributed by Chaohua Li",
    "text": "This section is contributed by Chaohua Li"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#create-synthetic-data",
    "href": "cdcdata-exercise/cdcdata-exercise.html#create-synthetic-data",
    "title": "CDC Data Exercise",
    "section": "Create synthetic data",
    "text": "Create synthetic data\nWe create a new dataset by scrambling the data from the original dataset. That means the values in each variable are sampled from the old values without replacement. Since the year, month, and days are considered the id for each observation, these variables won’t be scrambled.\n\n#Create data set left that contains jurisdiction, year, month and days \nleft&lt;-cause_of_death_data_clean[,c(1:4)]\n#Create data set right that contains numbers of deaths for different causes\nright&lt;-cause_of_death_data_clean[,-c(1:4)]\n#set seed for reproducible results\nset.seed(456)\n#define a new data frame synth that will contain scrambled values\nsynth &lt;- right\n#use a loop to scramble values without replacement in the dataset right \nfor (col in colnames(right)) {\n  #sample values without replacement for each variable\n  synth[[col]] &lt;- sample(right[[col]], replace = FALSE)\n}\n#combine dataset left with the scrambled data right\nsynth2 &lt;- cbind(left, synth)"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#summarizes-and-explores-the-synthetic-data",
    "href": "cdcdata-exercise/cdcdata-exercise.html#summarizes-and-explores-the-synthetic-data",
    "title": "CDC Data Exercise",
    "section": "Summarizes and explores the synthetic data",
    "text": "Summarizes and explores the synthetic data\nCalculating percentages for the total count for each cause of death.\n\n# Calculate percentages total\ncause_counts_total &lt;- synth2 %&gt;%\n  select(-c(`All Cause`, Year, Month, `Number Of Days`)) %&gt;%\n  gather(key = \"Cause of Death\", value = \"count\", -`Jurisdiction of Occurrence`) %&gt;%\n  group_by(`Cause of Death`) %&gt;%\n  summarize(total_count = sum(count, na.rm = TRUE)) %&gt;%\n  mutate(percentage = total_count / sum(total_count) * 100) %&gt;%\n  arrange(desc(total_count))\n\nRecreating a pie chart for the overall total for each cause of death.\n\n# Create pie chart \npie_chart_total &lt;- ggplot(cause_counts_total, aes(x = \"\", y = total_count, fill = `Cause of Death`)) +\n  geom_bar(stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(title = \"Synthetic Data: Distribution of \\nCauses of Death\",\n       fill = \"Cause of Death\",\n       x = NULL, y = NULL,) +\n  theme_void() +\n  theme(legend.position = \"right\",\n        legend.text = element_text(size = 8),  \n        legend.title = element_text(size = 10),  \n        legend.key.size = unit(0.5, \"lines\"), \n        plot.title = element_text(size = 16),  \n        plot.margin = margin(2, 6, 2, 2, \"cm\"),\n        legend.box.margin = margin(0, -10, 0, 0)) +  \n  guides(fill = guide_legend(\n    keywidth = unit(0.5, \"lines\"),  \n    label.position = \"right\",       \n    label.hjust = 0                 \n  )) +\n  scale_fill_discrete(labels = paste0(cause_counts_total$`Cause of Death`, \" (\", round(cause_counts_total$percentage), \"%)\"))\n\n# Adjustments\npie_chart_total &lt;- pie_chart_total + theme(\n  plot.margin = margin(2, 2, 2, 2, \"cm\"),\n  plot.title = element_text(size = 16, hjust = 0.5, margin = margin(0, 0, 10, 0)),\n  plot.caption = element_text(size = 10, hjust = 0.5, margin = margin(10, 0, 0, 0))\n)\n\n# Show pie chart\nprint(pie_chart_total)\n\n\n\n\n\n\n\n\nBecause each cause of death in the synthetic dataset contains exactly the same group of values, so the totals for each cause are the same with the original dataset.\n\nGrouping by month and cause of death, calculating total deaths per month, and calculating the percentage of total deaths each month. This is for graphing purposes.\n\n# Group by month and cause of death\ncause_counts_month &lt;- synth2 %&gt;%\n  select(-c(`All Cause`, Year, `Number Of Days`)) %&gt;%\n  gather(key = \"Cause of Death\", value = \"count\", -`Jurisdiction of Occurrence`, -Month) %&gt;%\n  group_by(Month, `Cause of Death`) %&gt;%\n  summarize(total_count = sum(count, na.rm = TRUE)) %&gt;%\n  mutate(Month = factor(month.name[Month], levels = month.name)) %&gt;%\n  arrange(Month, desc(total_count))\n\n# Calculate total deaths for each month\ntotal_deaths_month &lt;- cause_counts_month %&gt;%\n  group_by(Month) %&gt;%\n  summarise(total_deaths = sum(total_count))\n\n# Calculate percentage of total deaths for each month\ntotal_deaths_month &lt;- total_deaths_month %&gt;%\n  mutate(percentage = total_deaths / sum(total_deaths) * 100)\n\nPlot stacked bar plot for causes of death per month.\n\n# Create a stacked bar plot for causes of death by month\nggplot(cause_counts_month, aes(x = Month, y = total_count/1e6, fill = `Cause of Death`)) +\n  geom_bar(stat = \"identity\") +\n  scale_y_continuous(labels = function(x) paste0(format(x, big.mark = \",\", scientific = FALSE), \" million\"), \n                     breaks = pretty_breaks()) + \n  labs(title = \"Synthetic Data: Total Causes of \\nDeath by Month\",\n       x = \"Month\",\n       y = \"Total Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThis bar plot looks different from the one using original data, because the random sampling broke the association between month and deaths due to different causes.\nPlot bar graph for total number of deaths per month.\n\n# Plot the bar graph for total number of deaths per month.\nggplot(total_deaths_month, aes(x = Month, y = total_deaths/1e6, fill = Month)) +\n  geom_bar(stat = \"identity\") +\n  scale_y_continuous(labels = function(x) paste0(format(x, big.mark = \",\", scientific = FALSE), \" million\"), \n                     breaks = pretty_breaks()) +\n  labs(title = \"Synthetic Data:Total Deaths by Month\",\n       x = \"Month\",\n       y = \"Total Deaths\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nPrint table for total deaths per month.\n\n# Print table of total deaths per month.\nkable(total_deaths_month, \n      col.names = c(\"Month\", \"Total Deaths\", \"Percentage\"),\n      format = \"html\",\n      digits = 2,\n      caption = \"Synthetic Data:Total Deaths and Percentage by Month\") %&gt;%\n  kable_styling(full_width = FALSE) %&gt;%\n  scroll_box(height = \"200px\")\n\n\n\nSynthetic Data:Total Deaths and Percentage by Month\n\n\nMonth\nTotal Deaths\nPercentage\n\n\n\n\nJanuary\n1431480\n7.61\n\n\nFebruary\n1595078\n8.48\n\n\nMarch\n1465555\n7.79\n\n\nApril\n1480724\n7.87\n\n\nMay\n1504505\n7.99\n\n\nJune\n1646561\n8.75\n\n\nJuly\n1750683\n9.30\n\n\nAugust\n1623654\n8.63\n\n\nSeptember\n1619599\n8.61\n\n\nOctober\n1564062\n8.31\n\n\nNovember\n1572547\n8.36\n\n\nDecember\n1564330\n8.31\n\n\n\n\n\n\n\nDifferences in the distribution of deaths by month between original and synthetic data are also reflected in this table.\n\nGrouping by year and cause of death, calculating total deaths per year, and calculating the percentage of total deaths each year. This is for graphing purposes.\n\n# Group by year and cause of death\ncause_counts_year &lt;- synth2 %&gt;%\n  select(-c(`All Cause`, Month, `Number Of Days`)) %&gt;%\n  gather(key = \"Cause of Death\", value = \"count\", -`Jurisdiction of Occurrence`, -Year) %&gt;%\n  group_by(Year, `Cause of Death`) %&gt;%\n  summarize(total_count = sum(count, na.rm = TRUE)) %&gt;%\n  arrange(Year, desc(total_count))\n\n# Calculate total deaths for each year\ntotal_deaths_year &lt;- cause_counts_year %&gt;%\n  group_by(Year) %&gt;%\n  summarise(total_deaths = sum(total_count))\n\n# Calculate percentage of total deaths for each year\ntotal_deaths_year &lt;- total_deaths_year %&gt;%\n  mutate(percentage = total_deaths / sum(total_deaths) * 100)\n\nPlot bar graph for total number of death per year.\n\n# Plot bar graph for total number of deaths per year.\nggplot(total_deaths_year, aes(x = Year, y = total_deaths/1e6, fill = as.factor(Year))) +\n  geom_bar(stat = \"identity\") +\n  scale_y_continuous(labels = function(x) paste0(format(x, big.mark = \",\", scientific = FALSE), \" million\"), \n                     breaks = pretty_breaks()) +\n  labs(title = \"Synthetic Data:Total Deaths by Year\",\n       x = \"Year\",\n       y = \"Total Deaths\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe distribution of deaths by year using synthetic data is very similar to that in the original data. But the table below does show the numbers are slightly different from the original results.\n\nPrint table for total deaths per year.\n\n# Print table for total deaths per year.\nkable(total_deaths_year, \n      col.names = c(\"Year\", \"Total Deaths\", \"Percentage\"),\n      format = \"html\",\n      digits = 2,\n      caption = \"Synthetic Data:Total Deaths and Percentage by Year\") %&gt;%\n  kable_styling(full_width = FALSE) %&gt;%\n  scroll_box(height = \"200px\")\n\n\n\nSynthetic Data:Total Deaths and Percentage by Year\n\n\nYear\nTotal Deaths\nPercentage\n\n\n\n\n2020\n6193867\n32.91\n\n\n2021\n6531616\n34.71\n\n\n2022\n6093295\n32.38\n\n\n\n\n\n\n\n\nGrouping by month, year, and cause of death, calculating total deaths per year per month, and calculating the percentage of total deaths each year and month. This is for graphing purposes.\n\n# Group by year, month, and cause of death\ncause_counts_year_month &lt;- synth2 %&gt;%\n  select(-c(`All Cause`, `Number Of Days`)) %&gt;%\n  gather(key = \"Cause of Death\", value = \"count\", -`Jurisdiction of Occurrence`, -Year, -Month) %&gt;%\n  group_by(Year, Month, `Cause of Death`) %&gt;%\n  summarize(total_count = sum(count, na.rm = TRUE)) %&gt;%\n  arrange(Year, Month, desc(total_count))\n\n# Calculate total deaths for each year and month\ntotal_deaths_year_month &lt;- cause_counts_year_month %&gt;%\n  group_by(Year, Month) %&gt;%\n  summarise(total_deaths = sum(total_count))\n\n# Calculate percentage of total deaths for each year and month\ntotal_deaths_year_month &lt;- total_deaths_year_month %&gt;%\n  mutate(percentage = total_deaths / sum(total_deaths) * 100)\n\nPlot stacked bar plot for causes of death per month per year.\n\n# Create a stacked bar plot for causes of death by month and year\nggplot(cause_counts_year_month, aes(x = Month, y = total_count/1e6, fill = `Cause of Death`)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~Year) +  # facet by year\n  scale_y_continuous(labels = function(x) paste0(format(x, big.mark = \",\", scientific = FALSE), \" million\"), \n                     breaks = pretty_breaks()) + # format y-axis labels\n  labs(title = \"Synthetic Data:Total Causes of Death \\nby Month & Year\",\n       x = \"Month\",\n       y = \"Total Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThe distribution of deaths by year and month using synthetic data looks different from the original results. This is due to the random sampling process which broke the original pattern.\n\nPrint table for total deaths per month per year.\n\n# Print table for total deaths per month per year.\nkable(total_deaths_year_month, \n      col.names = c(\"Year\", \"Month\", \"Total Deaths\", \"Percentage\"),\n      format = \"html\",\n      digits = 2,\n      caption = \"Synthetic Data:Total Deaths and Percentage \\nby Year and Month\") %&gt;%\n  kable_styling(full_width = FALSE) %&gt;%\n  scroll_box(height = \"600px\")\n\n\n\nSynthetic Data:Total Deaths and Percentage by Year and Month\n\n\nYear\nMonth\nTotal Deaths\nPercentage\n\n\n\n\n2020\n1\n472058\n7.62\n\n\n2020\n2\n497446\n8.03\n\n\n2020\n3\n524118\n8.46\n\n\n2020\n4\n500293\n8.08\n\n\n2020\n5\n518146\n8.37\n\n\n2020\n6\n561612\n9.07\n\n\n2020\n7\n492192\n7.95\n\n\n2020\n8\n477343\n7.71\n\n\n2020\n9\n589829\n9.52\n\n\n2020\n10\n526264\n8.50\n\n\n2020\n11\n528635\n8.53\n\n\n2020\n12\n505931\n8.17\n\n\n2021\n1\n488815\n7.48\n\n\n2021\n2\n606530\n9.29\n\n\n2021\n3\n461131\n7.06\n\n\n2021\n4\n478082\n7.32\n\n\n2021\n5\n537713\n8.23\n\n\n2021\n6\n561448\n8.60\n\n\n2021\n7\n703027\n10.76\n\n\n2021\n8\n524714\n8.03\n\n\n2021\n9\n546985\n8.37\n\n\n2021\n10\n517421\n7.92\n\n\n2021\n11\n532602\n8.15\n\n\n2021\n12\n573148\n8.77\n\n\n2022\n1\n470607\n7.72\n\n\n2022\n2\n491102\n8.06\n\n\n2022\n3\n480306\n7.88\n\n\n2022\n4\n502349\n8.24\n\n\n2022\n5\n448646\n7.36\n\n\n2022\n6\n523501\n8.59\n\n\n2022\n7\n555464\n9.12\n\n\n2022\n8\n621597\n10.20\n\n\n2022\n9\n482785\n7.92\n\n\n2022\n10\n520377\n8.54\n\n\n2022\n11\n511310\n8.39\n\n\n2022\n12\n485251\n7.96"
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Background\nI’m Liza and I’m a first year non-thesis MS student in Bioinformatics. I earned my bachelor’s degree in Biology from Georgia Southern University in 2023. I’m not currently conducting any research, but I’m interested in forensics, microbiology, and infectious disease.\n\n\n\nExperience\nI am somewhat familiar with programming and data analysis. While my knowledge is far from extensive, I have encountered procedural and object based coding languages, and various forms of data analysis in my studies thus far. In this course I am hoping to add to and refine my current skill set in programming and data analysis.\n\n\n\nInterests & Fun Facts\nMy other interests include music, art, cooking, and Star Trek. Fun fact about me, I played trumpet in marching band during my undergrad. See below! :]"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "load dslabs package\nlibrary(dslabs) \nget help file for gapminder data\nhelp(gapminder) \nget overview of data structue\nstr(gapminder) \nget data summary\nsummary(gapminder) \ndetermine gapminder object type\nclass(gapminder)\n\nassign African countries to africadata\nsubset(gapminder, - creates a subset of gapminder dataframe\ncontinent == “Africa”) - filters data to only include African countries\nafricadata &lt;- subset(gapminder, continent == \"Africa\")\n\nreview data\nstr(africadata) - outputs info about africadata\nsummary(africadata) - outputs stats summary for africadata\nstr(africadata) \nsummary(africadata)\n\ncreate new objects\ninfmortality_lifeexpec &lt;-… - assigns results of operation to new variable\nafricadata[, c…] - subsets specific columns from data frame africadata\n(“infant_mortality”, “life_expectancy”) - specifies columns\ninfmortality_lifeexpec &lt;- africadata[, c(\"infant_mortality\", \"life_expectancy\")]\npopulation_lifeexpec &lt;-… - assigns results of operation to new variable\nafricadata[, c…] - subsets specific columns from data frame africadata\n(“population”, “life_expectancy”) - specifies columns\npopulation_lifeexpec &lt;- africadata[, c(\"population\", \"life_expectancy\")]\n\nreview data\nstr(infmortality_lifeexpec) - outputs info about infmortality_lifeexpec\nsummary(infmortality_lifeexpec) - outputs stats summary for infmortality_lifeexpec\nstr(infmortality_lifeexpec) \nsummary(infmortality_lifeexpec)\nstr(population_lifeexpec) - outputs info about population_lifeexpec\nsummary(population_lifeexpec) - outputs stats summary for population_lifeexpec\nstr(population_lifeexpec) \nsummary(population_lifeexpec)\n\nplot data\nplot(…) - creates plot\n(infmortality_lifeexpecSinfant_mortality,…) - takes infant_mortality data from variable infmortality_lifeexpec\n(…,infmortality_lifeexpecSlife_expectancy) - takes life_expectancy data from variable infmortality_lifeexpec\nmain - title of graph\nxlab - x axis title\nylab - y axis title\nplot(infmortality_lifeexpec$infant_mortality, infmortality_lifeexpec$life_expectancy, \n  main = \"Life Expectancy vs. Infant Morality\", \n  xlab = \"Infant Mortality\", \n  ylab = \"Life Expectancy\")\n\nplot(…) - creates plot\n(log10(population_lifeexpecSpopulation),…) - takes population data from variable population_lifeexpec, log scales data\n# (…,infmortality_lifeexpecSlife_expectancy) - takes life_expectancy data from variable infmortality_lifeexpec\n# main - title of graph\n# xlab - x axis title\n# ylab - y axis title\nplot(log10(population_lifeexpec$population), infmortality_lifeexpec$life_expectancy, \n  main = \"Life Expectancy vs. Population\", \n  xlab = \"Population (logscale)\", \n  ylab = \"Life Expectancy\")\n\n\nthere is a negative correlation between infant mortality and life expectancy.\nthere is a positive correlation between population size and life expectancy, as the population grows people live longer.\n\n\nfinding missing data\nmissing_data &lt;-… - assigns results of operation to new variable\nunique(africadataSyear[is.na(africadata$infant_mortality)]) - retreives uniquie data from african data for year only where na is true\nstr(missing_data) - outputs info about missing_data\nmissing_data &lt;- unique(africadata$year[is.na(africadata$infant_mortality)]) \nstr(missing_data)\n\nsingle year\ncreates a subset of africadata where the year = 2000\nafricadata_y2000 &lt;- subset(africadata, year == 2000)\nstr(africadata_y2000) - outputs info about africadata_y2000\nsummary(africadata_y20000) - outputs stats summary for africadata_y2000\nstr(africadata_y2000) \nsummary(africadata_y2000)\n\nplotting\nthis section follows above steps for variable creation and graphing but with data from africadata_y2000\ninfmortality_lifeexpec2000 &lt;- africadata_y2000[, c(\"infant_mortality\", \"life_expectancy\")] population_lifeexpec2000 &lt;- africadata_y2000[, c(\"population\", \"life_expectancy\")]\n\nplot(infmortality_lifeexpec2000Sinfant_mortality, infmortality_lifeexpec2000$life_expectancy,\n  main = \"Life Expectancy vs. Infant Morality\", \n  xlab = \"Infant Mortality\", \n  ylab = \"Life Expectancy\", \n  sub = \"Year 2000\")\n\nplot(log10(population_lifeexpec2000Spopulation), infmortality_lifeexpec2000$life_expectancy,\n  main = \"Life Expectancy vs. Population\", \n  xlab = \"Population (logscale)\", \n  ylab = \"Life Expectancy\", \n  sub = \"Year 2000\")\n\n\nsimple model fits\nfits model with infant mortality as predictor pulling data from africadata_y2000\nfit1 &lt;- lm(life_expectancy ~ infant_mortality, data = africadata_y2000) \nfits model with population size as predictor pulling data from africadata_y2000\nfit2 &lt;- lm(life_expectancy ~ population, data = africadata_y2000)\nsummary(fit1) - outputs stats summary for fit 1\nsummary(fit2) - outputs stats summary for fit 2\nsummary(fit1) \nsummary(fit2)\n\nbased on the p-values for each fit, fit 1 is a better model for the data.\n\n\nThis section is contributed by Ranni Tewfik.\nThis exercise uses the “us_contagious_diseases” dataset from the “dslabs” package. The dataset provides information on contagious diseases in the U.S. by state, year, and disease. There are six variables in the dataset: disease, state, year, weeks reporting, count, and population.\nPart 1 - Loading and Checking Data\n\n#Load the required packages\nlibrary(dslabs)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n#Look at help file for \"us_contagious_diseases\"\nhelp(us_contagious_diseases)\n\nstarting httpd help server ...\n\n\n done\n\n#Get an overview of data structure\nstr(us_contagious_diseases)\n\n'data.frame':   16065 obs. of  6 variables:\n $ disease        : Factor w/ 7 levels \"Hepatitis A\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ state          : Factor w/ 51 levels \"Alabama\",\"Alaska\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ year           : num  1966 1967 1968 1969 1970 ...\n $ weeks_reporting: num  50 49 52 49 51 51 45 45 45 46 ...\n $ count          : num  321 291 314 380 413 378 342 467 244 286 ...\n $ population     : num  3345787 3364130 3386068 3412450 3444165 ...\n\n#Get a summary of data\nsummary(us_contagious_diseases)\n\n        disease            state            year      weeks_reporting\n Hepatitis A:2346   Alabama   :  315   Min.   :1928   Min.   : 0.00  \n Measles    :3825   Alaska    :  315   1st Qu.:1950   1st Qu.:31.00  \n Mumps      :1785   Arizona   :  315   Median :1975   Median :46.00  \n Pertussis  :2856   Arkansas  :  315   Mean   :1971   Mean   :37.38  \n Polio      :2091   California:  315   3rd Qu.:1990   3rd Qu.:50.00  \n Rubella    :1887   Colorado  :  315   Max.   :2011   Max.   :52.00  \n Smallpox   :1275   (Other)   :14175                                 \n     count          population      \n Min.   :     0   Min.   :   86853  \n 1st Qu.:     7   1st Qu.: 1018755  \n Median :    69   Median : 2749249  \n Mean   :  1492   Mean   : 4107584  \n 3rd Qu.:   525   3rd Qu.: 4996229  \n Max.   :132342   Max.   :37607525  \n                  NA's   :214       \n\n#Determine the type of object \"us_contagious_diseases\" is\nclass(us_contagious_diseases)\n\n[1] \"data.frame\"\n\n\nPart 2 - Processing Data\n\n#Assign only Pertussis and Georgia in \"us_contagious_diseases\" to a new object\ngeorgia &lt;- subset(us_contagious_diseases, disease == \"Pertussis\" & state == \"Georgia\")\n\n#Get an overview of data structure and data summary for \"georgia\"\nstr(georgia)\n\n'data.frame':   56 obs. of  6 variables:\n $ disease        : Factor w/ 7 levels \"Hepatitis A\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ state          : Factor w/ 51 levels \"Alabama\",\"Alaska\",..: 11 11 11 11 11 11 11 11 11 11 ...\n $ year           : num  1938 1939 1940 1941 1942 ...\n $ weeks_reporting: num  51 52 51 51 51 52 52 51 50 50 ...\n $ count          : num  1922 1573 1114 1265 1288 ...\n $ population     : num  3066678 3095013 3123723 3152430 3181234 ...\n\nsummary(georgia)\n\n        disease          state         year      weeks_reporting\n Hepatitis A: 0   Georgia   :56   Min.   :1938   Min.   : 2.00  \n Measles    : 0   Alabama   : 0   1st Qu.:1952   1st Qu.:39.00  \n Mumps      : 0   Alaska    : 0   Median :1984   Median :46.50  \n Pertussis  :56   Arizona   : 0   Mean   :1978   Mean   :41.75  \n Polio      : 0   Arkansas  : 0   3rd Qu.:1997   3rd Qu.:49.25  \n Rubella    : 0   California: 0   Max.   :2011   Max.   :52.00  \n Smallpox   : 0   (Other)   : 0                                 \n     count          population     \n Min.   :   2.0   Min.   :3066678  \n 1st Qu.:  27.0   1st Qu.:3518196  \n Median :  58.0   Median :5776280  \n Mean   : 346.0   Mean   :5898795  \n 3rd Qu.: 571.5   3rd Qu.:7688876  \n Max.   :1922.0   Max.   :9830160  \n                                   \n\n#Create a new object that only contains year and count\ngeorgia1 &lt;- georgia %&gt;% select(\"year\", \"count\")\n  \n#Create a new object that only contains population and count\ngeorgia2 &lt;- georgia %&gt;% select(\"population\", \"count\")\n\n#Get an overview of data structure and data summary for \"georgia1\" and \"georgia2\"\nstr(georgia1)\n\n'data.frame':   56 obs. of  2 variables:\n $ year : num  1938 1939 1940 1941 1942 ...\n $ count: num  1922 1573 1114 1265 1288 ...\n\nsummary(georgia1)\n\n      year          count       \n Min.   :1938   Min.   :   2.0  \n 1st Qu.:1952   1st Qu.:  27.0  \n Median :1984   Median :  58.0  \n Mean   :1978   Mean   : 346.0  \n 3rd Qu.:1997   3rd Qu.: 571.5  \n Max.   :2011   Max.   :1922.0  \n\nstr(georgia2)\n\n'data.frame':   56 obs. of  2 variables:\n $ population: num  3066678 3095013 3123723 3152430 3181234 ...\n $ count     : num  1922 1573 1114 1265 1288 ...\n\nsummary(georgia2)\n\n   population          count       \n Min.   :3066678   Min.   :   2.0  \n 1st Qu.:3518196   1st Qu.:  27.0  \n Median :5776280   Median :  58.0  \n Mean   :5898795   Mean   : 346.0  \n 3rd Qu.:7688876   3rd Qu.: 571.5  \n Max.   :9830160   Max.   :1922.0  \n\n\nPart 3 - Plotting\n\n#Plot count as a function of year\nggplot(georgia1, aes(x = year, y = count)) + geom_point() + ggtitle(\"Total Number of Reported Cases of Pertussis in Georgia by Year\")\n\n\n\n\n\n\n\n\nThere is a negative correlation between year and count to a certain point in the plot, and then there is a break in the data (no available data for 1956-1973). After that point, there seems to be no correlation between year and count.\n\n#Plot count as a function of population\nggplot(georgia2, aes(x = log(population), y = count)) + geom_point() + ggtitle(\"Total Number of Reported Cases of Pertussis in Georgia by Population\")\n\n\n\n\n\n\n\n\nSimilar to the previous plot, there is a negative correlation between population and count to a certain point. However, there is a noticeable break in the data, and there seems to be no correlation between population and count after that point. This is because no data is available for the years 1956-1973.\nPart 4 - More Data Processing\n\n#Create a new object by extracting only the data for the years after 1973 from \"georgia\"\ngeorgia3 &lt;- georgia[(georgia$year &gt;= 1974),]\n\n\n#Get an overview of data structure and data summary for \"africadata3\"\nstr(georgia3)\n\n'data.frame':   38 obs. of  6 variables:\n $ disease        : Factor w/ 7 levels \"Hepatitis A\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ state          : Factor w/ 51 levels \"Alabama\",\"Alaska\",..: 11 11 11 11 11 11 11 11 11 11 ...\n $ year           : num  1974 1975 1976 1977 1978 ...\n $ weeks_reporting: num  6 7 2 19 33 29 40 27 22 48 ...\n $ count          : num  10 8 2 139 75 81 121 57 39 59 ...\n $ population     : num  4920562 5009127 5099141 5190101 5281471 ...\n\nsummary(georgia3)\n\n        disease          state         year      weeks_reporting\n Hepatitis A: 0   Georgia   :38   Min.   :1974   Min.   : 2.00  \n Measles    : 0   Alabama   : 0   1st Qu.:1983   1st Qu.:34.75  \n Mumps      : 0   Alaska    : 0   Median :1992   Median :42.50  \n Pertussis  :38   Arizona   : 0   Mean   :1992   Mean   :38.45  \n Polio      : 0   Arkansas  : 0   3rd Qu.:2002   3rd Qu.:47.75  \n Rubella    : 0   California: 0   Max.   :2011   Max.   :51.00  \n Smallpox   : 0   (Other)   : 0                                 \n     count          population     \n Min.   :  2.00   Min.   :4920562  \n 1st Qu.: 23.00   1st Qu.:5753480  \n Median : 40.00   Median :6852235  \n Mean   : 49.87   Mean   :7111873  \n 3rd Qu.: 58.50   3rd Qu.:8480435  \n Max.   :146.00   Max.   :9830160  \n                                   \n\n\nPart 5 - More Plotting\n\n#Plot count as a function of year for the years after 1973\nggplot(georgia3, aes(x = year, y = count)) + geom_point() + ggtitle(\"Total Number of Reported Cases of Pertussis in Georgia by Year After 1973\")\n\n\n\n\n\n\n\n\nThere is no noticeable correlation between year and count after 1973.\n\n#Plot count as a function of population for the years after 1973\nggplot(georgia3, aes(x = log(population), y = count)) + geom_point() + ggtitle(\"Total Number of Reported Cases of Pertussis in Georgia by Population After 1973\")\n\n\n\n\n\n\n\n\nThere is no noticeable correlation between population and count after 1973.\nPart 6 - Simple Model Fits\n\n#Fit count as the outcome and year as the predictor\nfit1 &lt;- glm(count ~ year, data = georgia3, family = poisson(link = \"log\"))\nsummary(fit1)\n\n\nCall:\nglm(formula = count ~ year, family = poisson(link = \"log\"), data = georgia3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  8.810681   4.174343   2.111   0.0348 *\nyear        -0.002460   0.002095  -1.174   0.2404  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1026.6  on 37  degrees of freedom\nResidual deviance: 1025.3  on 36  degrees of freedom\nAIC: 1235.8\n\nNumber of Fisher Scoring iterations: 5\n\n\nAfter 1973, count is not significantly associated with year (p-value = 0.24).\n\n#Fit count as the outcome and population as the predictor\nfit2 &lt;- glm(count ~ population, data = georgia3, family = poisson(link = \"log\"))\nsummary(fit2)\n\n\nCall:\nglm(formula = count ~ population, family = poisson(link = \"log\"), \n    data = georgia3)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.007e+00  1.089e-01  36.801   &lt;2e-16 ***\npopulation  -1.370e-08  1.503e-08  -0.912    0.362    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1026.6  on 37  degrees of freedom\nResidual deviance: 1025.8  on 36  degrees of freedom\nAIC: 1236.3\n\nNumber of Fisher Scoring iterations: 5\n\n\nAfter 1973, count is not significantly associated with population (p-value = 0.36)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Welcome! :]\nHello! This is my website and data analysis portfolio.\nUse the Menu Bar above to look around."
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda2.html",
    "href": "starter-analysis-exercise/code/eda-code/eda2.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/lizahall-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Hair Color            0             1   3   3     0        4          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 Age                   0             1  37.7 14.4  18  26  41  43   59 ▇▂▅▂▅\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\nb1&lt;- mydata %&gt;%\n  ggplot(mapping = aes(x = `Hair Color`, y = Height, fill = `Hair Color`)) +\n  geom_boxplot() +\n  scale_fill_manual(values = c(\"Blk\" = \"#1f78b4\", \"Bln\" = \"#33a02c\", \"Bro\" = \"#e31a1c\", \"Oth\" = \"#ff7f00\")) +\n  theme_minimal() +\n  labs(x = \"Hair Color\", y = \"Height\") +\n  ggtitle(\"Boxplot of Height by Hair Color\")\n  theme(plot.title = element_text(hjust = 0.5))  # Adjust title alignment\n\nList of 1\n $ plot.title:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nb1\n\n\n\n\n\n\n\n  # Saving the figure of the boxplot\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=b1) \n\nSaving 7 x 5 in image\n\n\n\ns1&lt;- ggplot(mydata, aes(x = Weight, y = Age, color = \"red\")) +\n  geom_point() +\n  stat_smooth(method = \"glm\", formula = y ~ x) +\n  ggtitle(\"Scatterplot with Smoothed Line: Weight vs Age\") +\n  labs(x = \"Weight\", y = \"Age\")\ns1\n\n\n\n\n\n\n\n  # Saving the figure of the scatter plot\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=s1) \n\nSaving 7 x 5 in image\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/lizahall-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 3 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`      \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                 \n1 Height          height in centimeters                 numeric value &gt;0 or NA\n2 Weight          weight in kilograms                   numeric value &gt;0 or NA\n3 Gender          identified gender (male/female/other) M/F/O/NA              \n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 3\n$ Height &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155\", …\n$ Weight &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\", \"M…\n\nsummary(rawdata)\n\n    Height              Weight          Gender         \n Length:14          Min.   :  45.0   Length:14         \n Class :character   1st Qu.:  55.0   Class :character  \n Mode  :character   Median :  70.0   Mode  :character  \n                    Mean   : 602.7                     \n                    3rd Qu.:  90.0                     \n                    Max.   :7000.0                     \n                    NA's   :1                          \n\nhead(rawdata)\n\n# A tibble: 6 × 3\n  Height Weight Gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 180        80 M     \n2 175        70 O     \n3 sixty      60 F     \n4 178        76 F     \n5 192        90 NA    \n6 6          55 F     \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55\n70\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains a simple made-up data-set in an Excel file.\nIt contains the variables Height, Weight and Gender of a few imaginary individuals.\nThe dataset purposefully contains some faulty entries that need to be cleaned.\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Liza's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  }
]